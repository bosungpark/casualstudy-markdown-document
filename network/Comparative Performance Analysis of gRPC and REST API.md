# Comparative Performance Analysis of gRPC and REST API Under Various Traffic Conditions and Data Sizes

## 출처
- **저널**: Journal of Applied Informatics and Computing (JAIC)
- **DOI**: https://doi.org/10.30871/jaic.v9i2.9276
- **저자**: Moch. Zukhruf Ain, Rizka Ardiansyah, Septiano Anggun Pratama, Muhammad Akbar, Nouval Trezandy Lapatta (Tadulako University, Indonesia)
- **게재**: Vol. 9 No. 2, April 2025, pp. 450-457
- **발표일**: 2025년 3월 25일
- **라이선스**: CC BY-SA 4.0
- **키워드**: gRPC, REST API, Web 3.0, Quantitative Analysis, HTTP/2

## 요약

### 1. 연구 배경

#### Web 3.0의 도전과제
**Web 3.0**는 탈중앙화 시스템에서 효율적인 데이터 교환이라는 과제를 제시한다. 기존 통신 프로토콜의 한계:

1. **REST API (HTTP/1.1)**:
   - 널리 사용됨 (광범위한 호환성)
   - 통신 비효율성 존재
   - 단순하고 이해하기 쉬움

2. **gRPC (HTTP/2)**:
   - 더 나은 성능 제공
   - Multiplexing 지원
   - Protocol Buffers 사용
   - 복잡한 설정

#### 연구 동기
마이크로서비스 아키텍처와 실시간 시스템의 증가로 인해 **어떤 프로토콜을 언제 사용해야 하는가**에 대한 명확한 가이드라인이 필요하다.

### 2. 연구 방법론

#### 실험 도구
1. **Apache JMeter**: 부하 테스트 및 성능 측정
2. **Wireshark**: 네트워크 패킷 분석 및 데이터 전송 효율성 측정

#### 측정 메트릭
1. **Throughput (처리량)**: 단위 시간당 처리된 요청 수 (req/min)
2. **Response Time (응답 시간)**: 요청에 대한 응답 시간 (ms)
3. **Latency (지연 시간)**: 네트워크 전송 지연 (ms)
4. **Data Transfer Efficiency (데이터 전송 효율성)**: 전송 속도 (KB/s)

#### 실험 시나리오
- **다양한 트래픽 조건**: 저부하, 중부하, 고부하
- **다양한 데이터 크기**: 작은 페이로드, 중간 페이로드, 큰 페이로드
- **정량적 접근법**: 통계적 분석 (ANOVA) 사용

### 3. 실험 결과

#### (1) Throughput 비교

**저트래픽 시나리오**:
- **REST API: 995 req/min**
- gRPC: 29.5 req/min
- **REST API가 33.7배 높음**

**분석**:
- REST API는 단순한 HTTP/1.1 프로토콜로 연결 설정이 빠름
- gRPC는 초기 연결 설정 (HTTP/2 핸드셰이크, TLS)에 오버헤드
- 저부하 환경에서는 단순성이 처리량 우위로 연결

#### (2) Response Time 비교

**GET 요청**:
- **REST API: 3 ms**
- gRPC: 20 ms
- **REST API가 6.7배 빠름**

**분석**:
- 단순 데이터 조회에서는 REST의 텍스트 기반 JSON이 오버헤드 적음
- gRPC의 Protocol Buffers 직렬화/역직렬화가 추가 시간 소요
- 작은 페이로드에서는 gRPC의 바이너리 효율성이 발휘되지 않음

#### (3) 대용량 데이터 전송 효율성

**큰 데이터 전송**:
- REST API: 134.1 KB/s
- **gRPC: 276.34 KB/s**
- **gRPC가 2.06배 빠름**

**분석**:
- gRPC의 **바이너리 직렬화** (Protocol Buffers)가 텍스트 기반 JSON보다 컴팩트
- HTTP/2의 **헤더 압축** (HPACK)이 오버헤드 감소
- **Multiplexing**으로 여러 스트림을 하나의 연결로 처리

#### (4) Latency (지연 시간)

**gRPC의 안정적 Latency**:
- gRPC: **0.147 ms (안정적)**
- REST API: 변동성 큼

**분석**:
- HTTP/2의 **스트림 우선순위**와 **흐름 제어**로 일관된 성능
- REST API는 HTTP/1.1의 HOL (Head-of-Line) blocking 문제
- 예측 가능한 latency는 실시간 시스템에 중요

#### (5) ANOVA 통계 분석

**결과**: **p > 0.05** (통계적으로 유의미한 차이 없음)

**해석**:
- 개별 메트릭에서는 차이가 있지만, **전체적인 성능 차이는 통계적으로 유의미하지 않음**
- 선택은 **use case에 따라 달라져야 함** (절대적 우위 없음)
- 트래픽 조건과 데이터 크기에 따라 각각의 장점이 다름

### 4. 사용 사례별 권장사항

#### REST API가 적합한 경우
1. **표준 웹 애플리케이션**:
   - 브라우저 기반 클라이언트
   - 단순한 CRUD 작업
   - 빠른 프로토타이핑

2. **저트래픽 환경**:
   - 작은 규모 서비스
   - 간헐적 요청
   - 처리량이 중요한 경우

3. **광범위한 호환성 필요**:
   - 다양한 클라이언트 지원
   - 레거시 시스템 통합
   - 공개 API

4. **빠른 GET 요청**:
   - 단순 데이터 조회
   - 캐싱 활용
   - 작은 페이로드

#### gRPC가 적합한 경우
1. **마이크로서비스 아키텍처**:
   - 서비스 간 통신
   - 내부 API (공개 API 아님)
   - 타입 안전성 중요

2. **실시간 시스템**:
   - 스트리밍 데이터
   - 양방향 통신
   - 낮고 안정적인 latency 요구

3. **대용량 데이터 전송**:
   - 큰 페이로드
   - 빈번한 대용량 전송
   - 네트워크 대역폭 효율성 중요

4. **고성능 요구사항**:
   - IoT 디바이스
   - 모바일 백엔드
   - 분산 시스템

### 5. 상세 비교 분석

#### REST API 장점
1. **단순성**: 
   - 이해하기 쉬움
   - 설정 간단
   - 디버깅 용이

2. **생태계**:
   - 풍부한 도구와 라이브러리
   - 광범위한 커뮤니티 지원
   - 표준화된 관행

3. **호환성**:
   - 모든 브라우저 지원
   - 프록시/방화벽 친화적
   - HTTP 표준 활용

4. **캐싱**:
   - HTTP 캐싱 메커니즘
   - CDN 활용 용이
   - ETag, Last-Modified 등

#### REST API 단점
1. **오버헤드**:
   - 텍스트 기반 JSON (파싱 비용)
   - 중복 헤더 전송
   - 비효율적 직렬화

2. **HTTP/1.1 제약**:
   - HOL blocking
   - 연결당 하나의 요청
   - 헤더 압축 없음

3. **확장성**:
   - 대규모 트래픽에서 비효율
   - 연결 오버헤드
   - 상태 관리 복잡

#### gRPC 장점
1. **성능**:
   - 바이너리 직렬화 (Protocol Buffers)
   - HTTP/2 multiplexing
   - 헤더 압축

2. **타입 안전성**:
   - .proto 파일로 스키마 정의
   - 컴파일 타임 검증
   - 자동 코드 생성

3. **양방향 스트리밍**:
   - 서버 → 클라이언트
   - 클라이언트 → 서버
   - 양방향 동시

4. **효율성**:
   - 낮은 latency
   - 높은 처리량 (큰 데이터)
   - 네트워크 대역폭 절약

#### gRPC 단점
1. **복잡성**:
   - 학습 곡선 가파름
   - 설정 복잡
   - 디버깅 어려움 (바이너리)

2. **브라우저 지원**:
   - 직접 지원 제한적
   - gRPC-Web 필요
   - 추가 프록시 계층

3. **생태계**:
   - REST 대비 작은 커뮤니티
   - 도구 부족
   - 표준화 진행 중

4. **방화벽/프록시**:
   - HTTP/2 차단 가능
   - 특수 설정 필요
   - 레거시 인프라 호환 문제

### 6. 성능 수치 요약표

| 메트릭 | REST API | gRPC | 우위 |
|--------|----------|------|------|
| **Throughput (저부하)** | 995 req/min | 29.5 req/min | REST (33.7배) |
| **GET Response Time** | 3 ms | 20 ms | REST (6.7배) |
| **대용량 전송 속도** | 134.1 KB/s | 276.34 KB/s | gRPC (2.06배) |
| **Latency 안정성** | 변동 큼 | 0.147 ms | gRPC |
| **ANOVA (p-value)** | > 0.05 | > 0.05 | 통계적 차이 없음 |

### 7. 실무 선택 가이드

#### 결정 플로우차트 (추정)

```
시작
 ↓
브라우저 클라이언트가 주요 사용자?
 ├─ Yes → REST API
 └─ No → 다음
        ↓
        대용량 데이터 전송이 빈번?
         ├─ Yes → gRPC
         └─ No → 다음
                ↓
                실시간/스트리밍 필요?
                 ├─ Yes → gRPC
                 └─ No → 다음
                        ↓
                        타입 안전성이 중요?
                         ├─ Yes → gRPC
                         └─ No → 다음
                                ↓
                                빠른 개발이 우선?
                                 ├─ Yes → REST API
                                 └─ No → gRPC (성능 최적화)
```

#### 하이브리드 접근법
많은 실제 시스템은 **두 프로토콜을 혼용**:

1. **공개 API**: REST API (호환성)
2. **내부 서비스 통신**: gRPC (성능)
3. **실시간 기능**: gRPC 스트리밍
4. **단순 조회**: REST API (캐싱)

예: Netflix, Google, Uber 등은 두 프로토콜을 상황에 맞게 사용

### 8. 한계점 및 향후 연구

#### 현재 연구의 한계
1. **제한된 환경**: 특정 하드웨어/네트워크 조건
2. **단순 시나리오**: 실제 프로덕션의 복잡성 미반영
3. **메트릭 제한**: CPU, 메모리 사용량 등 미측정
4. **단기 테스트**: 장기 안정성 미평가

#### 향후 연구 방향
1. **더 많은 메트릭**: CPU, 메모리, 디스크 I/O
2. **실제 워크로드**: 프로덕션 트래픽 패턴 시뮬레이션
3. **보안 측면**: TLS 오버헤드, 인증/인가 비용
4. **에러 처리**: 재시도, 타임아웃, 회복력 비교
5. **비용 분석**: 클라우드 환경에서 비용 효율성

## 내가 얻은 인사이트

### 1. "통계적 유의미성 없음(p > 0.05)"은 "차이 없음"이 아니다
ANOVA 결과가 p > 0.05라고 해서 REST와 gRPC가 같다는 뜻이 아니다:
- **개별 메트릭에서는 명확한 차이** (33배, 6배, 2배)
- **전체 분산이 크다**는 의미 → 상황에 따라 성능 차이가 크게 변동
- 실무 의미: **"언제나 좋은 것은 없다, use case에 따라 다르다"**

이는 벤치마킹의 중요한 교훈이다. 단일 메트릭이나 평균값으로 "A가 B보다 낫다"고 결론 내릴 수 없다.

### 2. REST의 저부하 우위(33배)는 "연결 오버헤드"를 의미한다
REST가 저트래픽에서 995 vs. 29.5 req/min으로 압도적 우위:
- gRPC는 **초기 연결 설정 비용**이 높음 (HTTP/2 핸드셰이크, TLS)
- 요청이 적으면 이 비용이 분산되지 않음
- 많은 요청이 오면 연결을 재사용하여 오버헤드 상쇄

**실무 의미**:
- **간헐적 API 호출** (크론 잡, 배치 작업): REST가 유리
- **지속적 연결** (WebSocket 대체, 스트리밍): gRPC 유리
- **Keep-alive 설정**이 gRPC 성능에 중요

### 3. gRPC의 대용량 우위(2배)는 "바이너리 + 압축"의 힘이다
276.34 vs. 134.1 KB/s의 차이는:
- **Protocol Buffers**: JSON 대비 5-10배 작은 크기
- **HPACK 헤더 압축**: HTTP/1.1은 매 요청마다 중복 헤더 전송
- **Multiplexing**: 여러 스트림을 하나의 TCP 연결로

**계산 예시**:
- JSON: `{"name": "John", "age": 30}` → ~30 bytes
- Protobuf: 동일 데이터 → ~5 bytes (필드 이름 없음, 바이너리)

네트워크 대역폭이 제한적인 환경 (모바일, IoT)에서 gRPC가 큰 이점.

### 4. GET 3ms vs. 20ms는 "직렬화 비용 vs. 전송 비용"의 trade-off다
REST가 GET에서 6.7배 빠른 이유:
- **작은 페이로드에서는 직렬화 비용이 지배적**
- JSON 파싱: 단순 (텍스트 그대로)
- Protobuf: 직렬화/역직렬화 필요 (CPU 사용)

**교차점 (Crossover point)**:
- 작은 데이터(<1KB): JSON이 빠름
- 큰 데이터(>10KB): Protobuf가 빠름 (전송 시간 절약 > 직렬화 비용)

이는 "항상 바이너리가 빠르다"는 오해를 깨는 중요한 발견이다.

### 5. "안정적 latency 0.147ms"는 실시간 시스템의 핵심이다
gRPC의 일관된 latency는:
- **예측 가능성** → SLA 보장 가능
- REST의 변동성 → 최악의 경우 대비 필요
- HTTP/2의 **스트림 우선순위**와 **흐름 제어**가 핵심

**실무 사례**:
- **게임 서버**: 16ms 프레임 시간 내 응답 필수 → gRPC
- **금융 거래**: 밀리초 차이가 수익에 영향 → gRPC
- **일반 웹앱**: 100ms 이내면 충분 → REST 괜찮음

### 6. 마이크로서비스에서 gRPC가 선호되는 이유는 "타입 안전성 + 성능"이다
논문에서 마이크로서비스 추천 이유:
1. **서비스 간 통신은 공개 API 아님** → 브라우저 호환성 불필요
2. **.proto 파일**로 계약 정의 → API 변경 시 컴파일 에러로 조기 발견
3. **자동 코드 생성** → 클라이언트/서버 코드 일관성
4. **대용량 데이터 교환** 빈번 → 전송 효율성 중요

**Netflix 사례**:
- 외부 API: REST (모바일 앱, 웹)
- 내부 서비스: gRPC (추천 엔진 ↔ 메타데이터 서비스)
- 이유: 내부는 초당 수백만 요청, 바이너리 효율성 필수

### 7. Web 3.0 맥락에서 gRPC는 "탈중앙화 노드 통신"에 적합하다
논문이 Web 3.0을 언급한 이유:
- **블록체인 노드 간 통신**: 대량의 트랜잭션/블록 데이터 동기화
- **스마트 컨트랙트 실행**: 낮은 latency로 상태 조회
- **IPFS 같은 분산 스토리지**: 큰 파일 청크 전송

**예시**:
- Ethereum 2.0: gRPC for consensus layer communication
- Cosmos SDK: gRPC endpoints for state queries
- Filecoin: gRPC for storage provider API

REST는 "사람 친화적" UI/API에, gRPC는 "기계 간" 통신에 유리.

### 8. "하이브리드 접근"이 현실적 해답이다
절대적 우위가 없으므로 (p > 0.05), 실무에서는:
- **API Gateway 패턴**: 외부는 REST, 내부는 gRPC
- **BFF (Backend for Frontend)**: 웹은 REST, 모바일은 gRPC
- **기능별 분리**: CRUD는 REST, 스트리밍은 gRPC

**구현 예시** (Envoy Proxy):
```
[브라우저] --REST--> [Envoy] --gRPC--> [마이크로서비스]
```
- Envoy가 REST ↔ gRPC 변환
- 클라이언트는 REST 편의성
- 백엔드는 gRPC 성능

### 9. Apache JMeter + Wireshark 조합은 "종합 성능 분석"의 표준이다
논문의 방법론:
- **JMeter**: 애플리케이션 레벨 메트릭 (throughput, response time)
- **Wireshark**: 네트워크 레벨 메트릭 (latency, packet loss)

이 조합의 가치:
- **상관관계 분석**: 높은 response time이 네트워크 문제인지 서버 문제인지 구분
- **프로토콜 검증**: HTTP/2 multiplexing이 실제로 작동하는지 확인
- **비용 없음**: 두 도구 모두 오픈소스

실무 팁: 성능 문제 디버깅 시 "애플리케이션 로그 + 네트워크 캡처"를 함께 보면 근본 원인 파악 빠름.

### 10. 이 연구의 진짜 가치는 "정량적 근거 제공"이다
많은 개발자가 "gRPC가 빠르다더라" 또는 "REST가 간단하다더라"는 주관적 의견에 의존한다. 이 논문은:
- **구체적 수치** 제공 (33배, 6배, 2배)
- **조건별 세분화** (저부하, 고부하, 작은 데이터, 큰 데이터)
- **통계적 검증** (ANOVA)

이런 정량적 근거가 있으면:
- **기술 선택 정당화**: "왜 gRPC를 써야 하나요?" → "대용량 전송에서 2배 빠릅니다"
- **성능 목표 설정**: "REST로 995 req/min 달성 가능한지 확인"
- **비용 계산**: "네트워크 대역폭 50% 절감 → 월 $X 절약"

**결론**: "좋은 벤치마크는 의사결정의 기초 데이터"이다. 이 논문처럼 명확한 수치가 있으면 감이 아닌 데이터로 아키텍처를 결정할 수 있다.
