# Leveraging LLMs for Formal Software Requirements: Challenges and Prospects

## 출처
- **링크**: https://arxiv.org/abs/2507.14330v2
- **저자**: Arshad Beg, Diarmuid O'Donoghue, Rosemary Monahan (Maynooth University)
- **게재**: 2025년 8월 (Overlay2025 Workshop)

---

## AI 요약

이 포지션 페이퍼는 LLM을 활용해 비형식적이고 모호한 자연어 소프트웨어 요구사항을 형식 검증 가능한 명세(formal verifiable specifications)로 자동/반자동 변환하는 VERIFAI 프로젝트의 도전과 전망을 제시한다. Formal verification은 model checker와 theorem prover로 구현이 명세에 부합하는지 수학적으로 증명하며, 항공우주/의료기기/자율시스템 같은 안전 중요 시스템 개발에 필수적이다. 하지만 formal specification 작성/유지보수가 어렵고 개발자 교육이 필요하며 소프트웨어 개발 주기를 최대 30% 증가시켜 산업 도입이 지속적으로 방해받아왔다. VERIFAI는 NLP, 온톨로지 기반 도메인 모델링, 아티팩트 재사용, LLM을 통합해 자연어 요구사항에서 형식 명세를 생성하고 추적성(traceability)을 지원한다.

**핵심 과제 5가지**: **C1 Semantic Ambiguity(의미론적 모호성)**은 자연어의 맥락 의존 용어, 암묵적 참조, 도메인 전문 용어가 요구사항 해석을 복잡하게 만들며, LLM이 사용자 의도를 오해하면 잘못된 출력이 발생한다. 구조화된 도메인 지식과 외부 온톨로지 정렬, human-in-the-loop 전략이 정확도 향상에 필요하다. **C2 Lack of Ground Truth Datasets(정답 데이터셋 부족)**는 IP 권리와 민감성 때문에 산업 기반 소프트웨어 공개 데이터셋이 희귀하고, 자연어 요구사항+formal logic 조합 표준 데이터셋 부족이 모델 학습/평가/재현성에 장애가 되며 확장성 문제를 야기한다. 다양한 산업/요구사항 유형을 포괄하는 고품질 annotated 데이터셋이 필수적이다. **C3 Tool Interoperability(도구 상호운용성)**는 형식 검증 도구들이 호환되지 않는 포맷과 제한된 통합 능력으로 end-to-end 자동화가 어렵고, 공유 표준이나 모듈식 파이프라인 부재로 수동/반자동 개입이 필요하다. 표준화된 인터페이스와 온톨로지가 원활한 도구 통합에 필요하다. **C4 Traceability Across Artefact Lifecycles(아티팩트 생애주기 추적성)**는 소프트웨어 개발 수명주기의 여러 단계에서 텍스트/모델/코드/테스트 간 추적성 유지가 수동으로는 시스템 무결성을 손상시키며, LLM이 영향 분석을 지원할 수 있지만 협업적/설명 가능한/맥락 인식 진화 프로세스가 필요하다. **C5 Explainability and User Trust(설명가능성과 사용자 신뢰)**는 LLM 생성 명세가 어떻게 도출되었고 의도한 의미를 반영하는지 이해가 필요한데 현재 모델은 투명성이 제한적이고 근거나 입력 귀속이 부족하다. 구현에 주석을 추가하거나 LLM으로 주석을 생성할 수 있지만 품질 검증에 human-in-the-loop가 필요하며, 특히 안전 중요 시스템에서 검사/개선/인간 감독이 요구된다.

**미래 방향 5가지**: **F1 Human-in-the-loop Formalisation(인간 참여 형식화)**는 반자동 형식화를 도메인 전문가가 안내하며 LLM이 논리 제안/추적 링크/개선 제안을 하고 사용자가 승인/수정한다. 이는 모호성 감소, 정확도 향상, 사용자 신뢰 증가를 보장하고 상호작용으로 모델 출력 개선을 통한 학습을 강화한다. 시각화/반복/피드백 지원으로 촉진되며 인간 판단이 중요 결정의 중심에 있어 새 방법론 채택을 촉진한다. **F2 Multi-modal Artefact Alignment(다중모달 아티팩트 정렬)**은 텍스트/다이어그램/테이블/스프레드시트 조합으로 문서화된 소프트웨어 요구사항 간 정렬이 모호성을 줄이고 더 나은 형식 명세를 만든다. 도구의 다중모달 지원은 표현 학습과 의미론적 매칭으로 달성되며, 구조적/시각적 모달리티를 가진 LLM이 맥락 해석을 개선해 더 포괄적인 모델을 만든다. 형식화 파이프라인과 중복 아티팩트 유형이 실제 복잡성을 모델링해 생성 명세의 정확성/신뢰성에 영향을 준다. **F3 Standardised Benchmarks(표준화 벤치마크)**는 C2와 일대일 대응되며 성능 시뮬레이션과 비교를 위한 표준 벤치마크 개발이 확립된 연구 영역이다. 합성 데이터셋이 부분 해결했지만 다양한 산업/요구사항 유형을 포괄하는 고품질 annotated 표준화 형식 명세 데이터셋 가용성이 제한적이다. 실제 소프트웨어 복잡성과 도메인 다양성을 포착하는 데이터셋이 분야 발전의 필수 구성요소가 될 것이다. **F4 Neuro-symbolic Reasoning(신경-심볼릭 추론)**은 LLM의 적응성과 심볼릭 추론의 정밀성을 결합하며, 신경망이 가능한 명세를 제안하고 논리 기반 도구가 이를 검증/개선한다. 일관성 개선, 제약 강제, 정확성 검증을 돕고 타입 규칙이나 도메인별 논리 같은 심볼릭 기능이 학습 과정을 안내한다. 구축이 복잡하지만 하이브리드 방법은 환각(hallucination) 감소와 명확성 향상 잠재력을 제공하며, 통계적 학습과 형식 방법을 통합한 신뢰할 수 있고 해석 가능한 모델로 이어질 수 있다. **F5 Interactive Traceability Tools(대화형 추적성 도구)**는 사용자 친화적 도구로 소프트웨어 요구사항 추적성을 개선하는 확립된 영역이며, 형식화 프로세스 시작부터 추적성을 내장해 요구사항을 모델/테스트/검증 결과에 연결한다. 디버깅/시스템 업데이트/감사를 지원하고 시각적 탐색/필터링/태깅이 변경 추적과 종속성 발견을 돕는다. LLM이 추적 링크 제안/불일치 플래깅/수정 설명으로 도울 수 있지만 사용자가 주요 결정을 통제해야 한다. 개발 환경 내에서 작동하고 팀 협업을 지원하며, 추적성이 명확하고 사용 가능하면 시스템 투명성을 높이고 항공우주/의료 같은 규제 분야에서 규정 준수를 보장한다. EARS, FRET, Doors 같은 산업 검증 도구가 있으며 산업 사례 연구가 향후 작업의 가치 있는 방향이다.

**문헌 종합**: 연구 질문은 RQ1(자연어 요구사항을 formal notation으로 변환하는 LLM 활용 방법론), RQ2(LLM을 이용한 형식 요구사항 형식화의 신흥 트렌드와 향후 연구 방향)이다. **도구별 접근**: GPT-3.5는 코드 검증을 위한 요구사항 분석을 지원하고, Explanation-Refiner는 LLM을 theorem prover와 통합해 NLI 검증과 반복 수정을 수행하며, GPT-4o+VeriFast는 functional specification 생성을 보여주나 중복성과 실패한 assertion으로 검증이 제한적이다. nl2spec은 비구조화 요구사항에서 interactive synthesis를 지원하고, SpecSyn은 sequence-to-sequence contract 생성을 21% 정확도 향상시키며, Req2Spec은 BOSCH 자동차 요구사항의 71%를 formal spec으로 변환한다. SpecGen은 prompt mutation과 verification feedback으로 LLM 생성 명세를 개선해 384개 벤치마크 프로그램 중 279개 성공하고, AssertLLM은 multi-phase prompting과 validation으로 89% 정확도의 assertion을 합성하며, SpecLLM은 VLSI 응용에서 spec review와 생성에 LLM을 활용한다. 스마트 그리드 요구사항은 GPT-4o와 Claude 3.5로 형식화해 F1 점수 79-94%를 달성했으며, 저자들은 GPT-4o와 Claude 3.5가 시스템 명세 복잡성 증가로 robust함을 유지하고 실제로 이득을 볼 수 있다고 관찰했다(모델 추론 깊이와 명세 풍부성 간 정렬 가능성). 이는 Gemini 1.5나 GPT-3.5-turbo에서 반영되지 않아 추가 조사가 필요하다. NASA 소프트웨어 검증은 요구사항 오류를 발견해 LLM-in-the-loop workflow의 실용성을 입증했다. **변환 기술**: NL-to-LTL 번역은 few-shot prompting과 dynamic reasoning으로 94.4% 정확도를 달성하고, NL-to-JML contract synthesis for Java는 유망한 결과를 보였다. 역사적 시스템 RSL, ARSENAL, RML은 초기 rule-based와 logic-based extraction pipeline을 입증했고, hybrid neuro-symbolic system은 더 큰 신뢰성을 제공한다. SAT-LLM은 SMT solver와 LLM을 결합해 F1 0.91로 불일치를 탐지하고, LeanDojo, ReProver, Thor는 retrieval-augmented generation과 LLM 안내 추론으로 formal proving을 강화한다. IDE 통합 노력으로 Copilot+PathCrawler+EVA는 반자동 ACSL spec 생성을 입증한다.

**주요 관찰**: Assertion 수준 합성이 전체 contract 생성보다 신뢰성이 높다. Laurel은 Dafny용 assertion을 50% 이상 성공률로 생성하고, AssertLLM은 contract type과 context로 안내 시 89% 이상 정확도를 초과한다. 전체 명세는 오류가 많아 여러 prompt 반복이나 외부 검증이 필요하다. 작은 범위와 잘 정의된 의미론이 더 나은 결과를 내며 assertion의 제한된 맥락이 검증 정확도 향상에 도움이 된다. LLM은 모호성이 줄어들고 더 넓은 시스템 지식 종속성이 적어 이런 작업을 더 신뢰성 있게 처리한다. 대형 프로그램 세그먼트의 end-to-end contract 합성은 여러 상호작용 컴포넌트나 함수 본문을 포함해 프로그램 의미론/논리/시간 경과 행동에 대한 깊은 이해가 필요하다. SpecGen과 SpecSyn은 상당한 진전을 보였지만 출력이 형식 검증에 사용 가능하기 전에 mutation operator나 human-in-the-loop(소프트웨어 테스팅 전문가 참여) 같은 후처리 단계가 필요하다. 노력 정확도는 도구 설계와 통합에 영향을 받으며, nl2spec은 단계별 개선으로 iterative와 user-in-the-loop 접근을 채택해 일부 LLM 한계를 해결한다. Guided template이나 Chain-of-Thought를 활용한 prompt engineering 기법은 출력 일관성과 정확성 개선을 약속했지만 이런 전략은 assertion 합성이나 좁은 범위 설명 같은 지역화된 작업에서 잘 작동한다. 프로그램 크기와 명세 목표 복잡성이 증가하면 모호성/under-specification/논리 불일치 가능성이 증가한다. 현재 LLM 아키텍처는 집중된 선언적 작업에서 뛰어나지만 더 넓은 명세 목표에는 증강이 필요하다. 문헌 종합으로 LLM 강점, 심볼릭 추론, 반복적 사용자 상호작용을 결합하는 연구 트렌드가 증가한다고 결론 내릴 수 있다. 현재 assertion 생성이 정확도와 사용성에서 우위지만 더 나은 prompt 설계, 도메인별 fine-tuning, verifier-in-the-loop의 병렬 노력이 프로세스 성능을 밀접하게 맞춘다. 추상화와 일관성 도전이 이 영역의 연구 노력을 이끈다.

**Prompting 전략**: Zero-shot prompting이 기본 성능에서 강하고, Chain-of-Thought(CoT) prompting은 중간 단계로 논리 흐름을 개선하지만 긴 프롬프트에서 맥락 붕괴("lost-in-the-middle")를 겪는다. One-shot, few-shot, SCoT는 대안적 trade-off를 제공하지만 zero-shot이 종종 경쟁력을 유지한다. 고급 prompting 방법으로 Automate-CoT는 CoT 예제를 자동 생성하고, Reprompting은 Gibbs sampling으로 prompt local optima를 탈출하며, graph와 tree를 이용한 structured prompting은 추론 robust성과 효율성을 개선한다. RAG(Retrieval-Augmented Generation)는 지식 집약적 합성을 위한 grounding을 개선하고, LoRA를 통한 fine-tuning은 경량 도메인 적응을 가능하게 한다.

**실험 평가**: Appendix B는 Frama-C Tutorial의 36개 예제에서 4개 SMT solver(Alt-Ergo, Z3, CVC4, CVC5) 성능 비교를 제시한다. Tritype.c 프로그램 분석에서 PathCrawler는 all-path coverage 기준으로 성공적으로 계측/분석했고 100% branch coverage를 달성했지만 11개 생성 테스트 케이스 중 어느 것도 성공/실패로 분류되지 않고 모두 "unknown"으로 남았다. 이는 도구가 코드의 모든 분기를 실행했지만 사후 조건 명세 불완전이나 반환 값 해석 모호성 때문에 어떤 특정 경로도 verdict를 결정적으로 결정할 수 없었음을 의미한다. 19개 총 경로 중 11개 커버, 8개 infeasible로 표시되어 제어 흐름 복잡성을 강조한다. 경로를 결정적으로 평가할 수 없는 것은 입력 제약 개선이나 symbolic execution 한계 추가 조사가 필요함을 나타낸다. **baseline_Example1-Tritype.c** 검증은 최소 ACSL 명세로 termination과 unreachability 2개 암묵적 검증 목표만 생성되어 4개 prover 모두 성공적으로 검증했다. 함수가 구문적으로 잘 형성되었고 무한 루프나 도달 불가 코드 같은 trivial 문제가 없음을 나타내지만, 사용자 정의 postcondition/precondition 부재로 분석이 기능 정확성에 대한 제한된 통찰을 제공한다. missing assigns clause 경고는 메모리 부작용이 지정되지 않아 호출자에게 부정확한 가정을 야기할 수 있고, RTE(Run-Time Error) guard 부재는 overflow나 0으로 나누기 같은 일반 runtime error가 검증되지 않음을 나타낸다. 결과는 구조적 수준에서 soundness를 입증하지만 깊은 명세 부족이 검증 유용성을 크게 제한한다. 모든 prover가 이런 trivial 조건에서 동등하게 수행한다. **pathcrawler_augmented_Example1-Tritype.c**는 상세한 ACSL 주석으로 풍부해져 상당히 다른 검증 행동을 보인다. 20개 목표가 생성되었으며(18개는 사용자 지정 precondition/postcondition 기반, termination/unreachability 표준 검증 추가), prover 효과성에 뚜렷한 분할을 보여준다. 모든 prover가 termination과 기본 논리를 검증했지만 복잡한 ensures clause 처리 능력이 달랐다. Z3와 CVC4는 각각 7개 목표 검증 실패(Z3는 timeout, CVC4는 unknown 상태)로 복잡한 논리 경로와 case 구분 처리에 어려움을 겪었다. Alt-Ergo와 CVC5는 약간 나아 각각 5개 미검증 목표만 남겼다. 가장 복잡한 속성(삼각형 유형 올바른 분류 - Scalene, Isosceles, Equilateral - 와 부등식 규칙 처리)은 모든 prover에서 일관되게 문제가 되어 solver가 disjunction-heavy 논리나 기능 명세에 내장된 미묘한 산술 제약을 다룰 때 직면하는 도전을 반영한다. **실행 시간**: CVC5가 대부분 프로그램에서 가장 빠르고(0.001-0.064초), Alt-Ergo/Z3/CVC4는 유사한 범위(0.01-0.30초)이며 binary_search가 가장 느리다(0.25-0.30초, CVC5 0.064초). 실행 시간 그래프는 CVC5의 일관된 우수성을 시각적으로 확인한다.

**결론**: 의미론적 모호성, 정답 데이터 부족, 도구 상호운용성, 생애주기 추적성, 설명가능성이 완전 자동화의 주요 장벽이지만 각 도전은 혁신의 비옥한 토양을 제시한다. Human-in-the-loop 시스템, 다중모달 정렬, 표준화 벤치마크, 신경-심볼릭 추론, 대화형 추적성 도구 같은 미래 방향이 실용적이고 확장 가능한 경로를 제공한다. AI와 formal method가 계속 수렴하면서 학제 간 협력이 격차를 메우고 개념적 발전을 강력한 실제 솔루션으로 전환하는 핵심이 될 것이다.

---

## 내가 얻은 인사이트

1. **Assertion vs Full Contract 생성의 명확한 난이도 차이**: AssertLLM(89%)과 Laurel(50%+)처럼 assertion-level 합성은 높은 정확도를 달성하지만, full contract 생성은 여러 prompt 반복과 외부 검증이 필요할 정도로 오류가 많다. 작은 범위와 잘 정의된 의미론이 LLM에게 더 나은 결과를 내며, 이는 환각 탐지 논문들에서 span-level detection이 document-level보다 정확한 패턴과 유사하다. 복잡성이 증가하면 모호성/under-specification/논리 불일치 가능성이 증가하는 것은 LLM의 근본적 한계를 보여준다.

2. **Human-in-the-loop이 형식 검증 분야에서도 핵심이다**: F1이 제시하는 반자동 형식화는 LLM이 논리/추적 링크/개선을 제안하고 도메인 전문가가 승인/수정하는 방식으로, 가드레일의 ICD(In-Context Defense)나 RA-LLM(Robustly Aligned LLM)의 human oversight와 철학이 같다. 이는 안전 중요 시스템(safety-critical systems)에서 LLM 단독 신뢰가 불가능하고 인간 판단이 중요 결정의 중심에 있어야 함을 의미하며, formal verification이라는 수학적 증명 영역에서도 LLM이 완전 자동화를 달성하지 못한다는 현실을 보여준다.

3. **Prompting 전략의 Trade-off가 명확하다**: Zero-shot이 기본 성능에서 강하고, CoT는 논리 흐름을 개선하지만 "lost-in-the-middle"로 긴 프롬프트에서 맥락 붕괴를 겪으며, few-shot은 대안적 trade-off를 제공하지만 zero-shot이 종종 경쟁력을 유지한다. 이는 Safeguarding Survey의 prompting 전략 분석과 일치하며, Automate-CoT(자동 CoT 예제 생성), Reprompting(Gibbs sampling으로 local optima 탈출), structured prompting(graph/tree로 추론 robust성 개선)이 고급 기법으로 제시된다. RAG는 지식 집약적 합성의 grounding을 개선하고 LoRA는 경량 도메인 적응을 가능하게 한다.

4. **Neuro-symbolic이 LLM 한계를 보완하는 핵심 방향이다**: F4가 제안하는 신경-심볼릭 추론은 신경망이 가능한 명세를 제안하고 논리 기반 도구가 검증/개선하는 방식으로, LLM의 적응성과 심볼릭 추론의 정밀성을 결합한다. 이는 Safeguarding Survey의 neural-symbolic approach와 동일한 개념이며, SAT-LLM(SMT solver + LLM으로 F1 0.91 불일치 탐지), LeanDojo/ReProver/Thor(retrieval-augmented generation + LLM 안내 추론)가 실제 구현 사례다. 타입 규칙이나 도메인별 논리 같은 심볼릭 기능이 학습 과정을 안내해 환각 감소와 명확성 향상을 달성하며, 통계적 학습과 형식 방법을 통합한 신뢰할 수 있고 해석 가능한 모델로 이어질 수 있다.

5. **SMT Solver 비교가 실용적 가치를 제공한다**: Appendix B의 36개 프로그램 실험에서 CVC5가 대부분에서 가장 빠르고(0.001-0.064초), Alt-Ergo/Z3/CVC4는 유사한 범위(0.01-0.30초)로, Z3와 CVC4가 복잡한 ensures clause 처리에서 timeout/unknown으로 7개씩 실패한 반면 Alt-Ergo와 CVC5는 5개만 실패했다. 이는 형식 검증 파이프라인 구축 시 prover 선택이 검증 성공률과 실행 시간에 직접 영향을 미치며, 특히 disjunction-heavy 논리나 미묘한 산술 제약에서 solver 간 성능 차이가 크다는 실용적 교훈을 제공한다. PathCrawler의 100% branch coverage 달성했지만 11개 테스트 모두 "unknown" verdict는 symbolic execution의 한계를 보여준다.
