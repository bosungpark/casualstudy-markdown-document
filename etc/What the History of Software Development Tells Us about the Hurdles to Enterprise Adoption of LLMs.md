# What the History of Software Development Tells Us about the Hurdles to Enterprise Adoption of LLMs

## 출처

* **링크**: [https://maverickventures.medium.com/what-the-history-of-software-development-tells-us-about-the-hurdles-to-enterprise-adoption-of-llms-c96bc968456d](https://maverickventures.medium.com/what-the-history-of-software-development-tells-us-about-the-hurdles-to-enterprise-adoption-of-llms-c96bc968456d) ([Medium][1])

---

## AI 요약

### 1) 엔터프라이즈 LLM 도입이 느린 이유

벤치마크/프로토타입 수준은 빠르지만, **실제 운영 환경에 배포해 지속적으로 가치 제공까지 가는 과정에서 도구·프로세스가 부족**하다. 특히 **테스트·평가·모니터링**이 구축돼 있지 않아 엔터프라이즈 도입이 지연되고 있다. ([Medium][1])

### 2) SDLC(전통 소프트웨어 개발 생명주기)에서 나온 교훈

1970년대 워터폴 → 2001년 애자일 → 2009년 데브옵스 순으로 개발 프로세스가 진화하며 도구/프로세스가 **테스트·배포·협업·지속적 전달**을 뒷받침했다. 이 전통적 진화 덕분에 “소프트웨어가 기업의 핵심 자산이 되는 시대”가 열렸다. ([Medium][1])

### 3) LLM App Development Life Cycle의 구조적 차이

LLM 개발은 데이터 의존도 낮아 빠른 프로토타입 생성은 쉬우나, **출력 평가가 분류보다 훨씬 복잡**하고 변화가 빠르며, 사용자 입력/출력의 불규칙성이 크다. 이 때문에 전통적 테스트·QA 방법이 그대로 적용되지 않는다. ([Medium][1])

### 4) 평가·모니터링이 Adoption 장벽

* 평가(Evaluation): 모델/시스템 성능을 정량적으로 판단할 수 있는 일관된 지표/프로세스 부족
* 테스트(Test): 기계적 버그 검사·통합 테스트는 가능하나 **생성 결과의 품질 판단**이 어려움
* 모니터링(Observability): 사용자 응답/시스템 실제 동작을 제대로 추적·해석할 도구 부족
  결과적으로 엔터프라이즈는 **LLM 도입 리스크·비용을 스스로 해결해야 하고, 그 부담이 너무 큼**. ([Medium][1])

### 5) 시장 기회와 수요

약 35명의 엔지니어 설문/인터뷰에서 **모델 평가가 도입 장애 요인 1위**로 꼽혔고, **96% 기업이 외부 평가/관찰 도구에 비용 지불 의향**이 있었다. 평가 툴 시장은 수백만 달러 규모로 예상된다. ([Medium][1])

### 6) 생태계 방향성

엔터프라이즈는 자체 구축보다 **통합된 평가·관찰 솔루션을 원하며**, 포인트 솔루션이 아니라 **전체 LLM 개발 → 배포 → 운영까지 커버하는 도구 체계**를 찾고 있다. ([Medium][1])

---

## 내가 얻은 인사이트

### 1) 엔터프라이즈 도입은 “출력의 품질·신뢰” 보장부터 시작해야 한다

프로토타입이 아니라 **엔터프라이즈 가치 제공** 단계까지 가려면 단순 생성 정확도보다, 그 출력이 **비즈니스 문맥에서 의미 있고 신뢰할 수 있어야 한다**는 것을 증명해야 한다.

* 제품 설계 시 “정확도 지표”만이 아니라 **Factuality, Relevance, Coherence, 안전성** 같은 정량적 메트릭을 기본 KPI로 설정한다.
* 모델 출력이 업무 결과에 어떤 영향을 주는지 **비즈니스 KPI로 연결**하는 평가 프레임워크를 설계한다.

### 2) 평가·테스트·모니터링 루프를 제품 워크플로우 한가운데 둬라

엔터프라이즈는 검증 불가능한 시스템을 신뢰하지 않는다.

* **자동·수동 평가 도구**를 내장해 “사용자·엔지니어가 반복적으로 품질을 측정하고 개선”할 수 있도록 한다.
* 운영 시스템에서도 **실제 응답에 대한 모니터링 및 오류 검출**이 즉시 가능해야 사용자 불만/리스크를 줄인다.
* 평가 결과를 **대시보드, 알람, SLA 지표**로 실시간 시각화한다.

### 3) “도구의 일관성”이 Adoption 속도를 높인다

엔터프라이즈 고객은 다양한 도구를 조합하는 대신 **단일 프레임워크/데이터 체계**를 선호한다.

* 점진적 기능 추가형이 아닌 **통합된 평가-테스트-모니터링 체계** 제공을 목표로 한다.
* API/프레임워크 중립적으로 **다양한 LLM/데이터 소스**를 연결할 수 있게 설계한다.

### 4) 벤치마크는 시작점이지 결론이 아니다

기존 LLM 벤치마크는 일반적 성능을 보여줄 뿐, **특정 업무/도메인에서의 신뢰성**을 평가하지 못한다.

* 고객의 실제 도메인 데이터를 반영한 **맞춤형 평가 세트**를 제품 초기부터 설계해두면 도입 신뢰를 빠르게 획득할 수 있다.
* 정량화된 평가 결과를 **영업·성공 사례로 활용**한다.

### 5) 엔터프라이즈 가치 증명은 “투명한 품질 데이터”에서 나온다

임팩트를 보여주는 것은 기능 목록이 아니라 **품질·신뢰·ROI 지표의 개선**이다.

* 제품 로드맵에 **검증 루프 확장, 품질 지표 개선, 에러/위험 감소율**과 같은 실증 지표를 포함한다.
* SLA/계약 단계에서 **평가·모니터링 품질 목표**를 명시해 엔터프라이즈가 도입을 확신하도록 돕는다.
